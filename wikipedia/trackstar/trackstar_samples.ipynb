{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37eb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackstarUnbatched:\n",
    "    def __init__(self, model, device='cuda', eps=1e-8):\n",
    "        # disable caching so forward is purely stateless\n",
    "        \n",
    "        self.model = model.to(device).eval()\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "        self.second_moment = None\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        self.projector = None\n",
    "        self.counter = 0\n",
    "        self.grouped_grads = []\n",
    "        print('Initialized TrackStar Class')\n",
    "\n",
    "    def compute_gradients(self, sample, group_size=2, prompt_length=0):\n",
    "        self.model.zero_grad()\n",
    "        input_ids = torch.tensor(sample['input_ids']).to(self.device)\n",
    "        attention_mask = torch.ones_like(input_ids).to(self.device)\n",
    "        x_in = input_ids[:, :-1]\n",
    "        y    = input_ids[:, 1:]\n",
    "        m    = attention_mask[:, :-1]\n",
    "        labels = y.clone()\n",
    "        labels[:, :prompt_length] = -100  \n",
    "        logits = self.model(input_ids=x_in, attention_mask=m).logits\n",
    "        loss = self.loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))  \n",
    "        loss = loss / (labels != -100).sum()  \n",
    "        loss.backward()\n",
    "        \n",
    "        # collect per-param grads\n",
    "        block_grads = defaultdict(list)\n",
    "        for name, p in self.model.named_parameters():\n",
    "            if p.grad is None or 'wte' in name: continue\n",
    "            g = p.grad.detach().flatten()\n",
    "            if name.startswith('transformer.h.'):\n",
    "                L = int(name.split('.')[2])\n",
    "                b = L // group_size\n",
    "                t = 'attn' if 'attn' in name else 'mlp'\n",
    "                key = f'group{b}_{t}'\n",
    "            elif name.startswith('transformer.ln_f'):\n",
    "                key = 'final_ln'\n",
    "            elif name.startswith('transformer.lm_head'):\n",
    "                key = 'lm_head'\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            block_grads[key].append(g)\n",
    "        block_grads = {k: torch.cat(v, dim=0) for k, v in block_grads.items()}\n",
    "    \n",
    "        block_grads = {key: g/(self.second_moment[key].to(self.device) + self.eps) for key, g in block_grads.items()}\n",
    "        block_grads = self.projector.project_per_block(block_grads)\n",
    "      \n",
    "        self.grouped_grads.append(block_grads)\n",
    "        return self.grouped_grads  \n",
    "\n",
    "\n",
    "def compute_block_shapes(grouped_second_moment, embedding_dim):\n",
    "    block_shapes = {}\n",
    "    for key, vec in grouped_second_moment.items():\n",
    "        total_dim = vec.numel()\n",
    "        n = embedding_dim\n",
    "        if total_dim % n != 0:\n",
    "            raise ValueError(f\"Dimension mismatch in {key}: total {total_dim} not divisible by embedding_dim {n}\")\n",
    "        m = total_dim // n\n",
    "\n",
    "        block_shapes[key] = (m, n)\n",
    "    return block_shapes\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Second Moment Computation and grouping. \n",
    "## Compute block shapes from grouped second moments\n",
    "## Use these block shapes to initialize a BlockProjector which essentially initializes projection matrices for each block\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('out/wiki_model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae703b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "second_moment = torch.load('data/trackstar/wiki/second_moment.pt', map_location='cpu')\n",
    "for k, vec in second_moment.items():\n",
    "    print(f\"{k:12s} → {tuple(vec.shape)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f02fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "class BlockProjector:\n",
    "    def __init__(self, block_shapes, d=4096, device='cpu'):\n",
    "        self.d = d\n",
    "        self.sqrt_d = int(math.sqrt(d))\n",
    "        self.device = device\n",
    "        self.proj_matrices = {}\n",
    "        torch.manual_seed(0)\n",
    "        for key, (m, n) in block_shapes.items():\n",
    "            P0 = torch.randn(self.sqrt_d, m, device=device) / math.sqrt(self.sqrt_d)\n",
    "            P1 = torch.randn(self.sqrt_d, n, device=device) / math.sqrt(self.sqrt_d)\n",
    "            self.proj_matrices[key] = (P0, P1)\n",
    "            \n",
    "        \n",
    "    def project_per_block(self, block_grads):\n",
    "\n",
    "        out = {}\n",
    "        for key, vec in block_grads.items():\n",
    "            P0, P1 = self.proj_matrices[key]\n",
    "            m, n = P0.shape[1], P1.shape[1]\n",
    "            W = vec.view(m, n)\n",
    "            out[key] = (P0 @ W @ P1.T).flatten()   # → [d]\n",
    "        return out\n",
    "\n",
    "def group_second_moment(second_moment: dict[str, torch.Tensor],\n",
    "                        group_size: int) -> dict[str, torch.Tensor]:\n",
    "    pattern = re.compile(r\"^group(\\d+)_(attn|mlp)$\")\n",
    "    bucketed: dict[str, list[torch.Tensor]] = defaultdict(list)\n",
    "\n",
    "    for key, vec in second_moment.items():\n",
    "        m = pattern.match(key)\n",
    "        if m:\n",
    "            layer = int(m.group(1))\n",
    "            typ   = m.group(2)                    # 'attn' or 'mlp'\n",
    "            new_layer = layer // group_size       # 0,1,2,...\n",
    "            new_key   = f\"group{new_layer}_{typ}\"\n",
    "        else:\n",
    "            # keep other parameters (final_ln, lm_head) as is\n",
    "            new_key = key\n",
    "\n",
    "        bucketed[new_key].append(vec)\n",
    "\n",
    "    # concatenate each list of tensors into one vector\n",
    "    return {k: torch.cat(vs, dim=0) for k, vs in bucketed.items()}\n",
    "\n",
    "\n",
    "\n",
    "grouped_second_moment = group_second_moment(second_moment, 2)\n",
    "for k, vec in grouped_second_moment.items():\n",
    "    print(k, vec.shape)\n",
    "block_shapes = compute_block_shapes(grouped_second_moment, model.config.n_embd)\n",
    "proj = BlockProjector(block_shapes, d=4096, device='cpu')\n",
    "\n",
    "## Compute projected gradients\n",
    "## Go through the dataset in batches \n",
    "## For each batch, compute the gradient of each sample in the batch and group the gradients by blocks defined before\n",
    "## For each gradient in the batch, normalize it with its corresponding second moment block\n",
    "## Each gradient is essentially a dictionary of grouped block names, which will be passed to the projector\n",
    "## Projector is initialized before and projects each gradient dictionary and appends it to a list of gradients. \n",
    "## Once the list reaches a certain cutoff, store it in a file. \n",
    "\n",
    "trackstar = TrackstarUnbatched(model, device='cpu')\n",
    "trackstar.second_moment = grouped_second_moment\n",
    "trackstar.projector = proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_corr_matrix = torch.load('data/trackstar/wiki/gradients/autocorr_matrices_inv_sqrt.pt', map_location='cpu')\n",
    "print(auto_corr_matrix.keys())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599170e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    'everest',\n",
    "    'jazz',\n",
    "    'ancient_rome',\n",
    "    'dna',\n",
    "    'feminism',\n",
    "    'impressionism',\n",
    "    'internet',\n",
    "    'philosophy_mind',\n",
    "    'solar_system',\n",
    "    'ww2',\n",
    "    'thermodynamics',\n",
    "    'iss_dot_model',\n",
    "    'ww1_dot_model',\n",
    "    'ancient_egypt',\n",
    "    'ancient_greece',\n",
    "    'art_deco',\n",
    "    'big_bang',\n",
    "    'buddhism',\n",
    "    'democracy',\n",
    "    'ecology',\n",
    "    'genetics',\n",
    "    'gothic_architecture',\n",
    "    'probability',\n",
    "    'renaissance',\n",
    "    'shakespeare'\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    ckpt = torch.load(f'out/wiki_models_finetuned/fisher_regularized_models/{example}_finetuned_fisher.pt', map_location='cpu')\n",
    "    output_ids = ckpt['output_ids']\n",
    "    output_text = tokenizer.decode(output_ids[0])\n",
    "    print(output_text)\n",
    "    split_text = output_text.split('.')[0]\n",
    "    prompt = split_text + '.'\n",
    "    prompt_length = len(tokenizer.encode(prompt))\n",
    "    sample = {\n",
    "        'input_ids': output_ids\n",
    "    }\n",
    "    gradient_query_sample = trackstar.compute_gradients(sample, group_size=2, prompt_length=prompt_length)\n",
    "    sample_gradient = {}\n",
    "    for key, R in auto_corr_matrix.items():\n",
    "        grad = torch.tensor(R).to('cpu') @ gradient_query_sample[-1][key].to('cpu')\n",
    "        norm = torch.norm(grad, dim=0, keepdim=True)\n",
    "        sample_gradient[key] = grad / norm\n",
    "    torch.save(sample_gradient, f'data/trackstar/wiki/testing/gradients/{example}_gradient.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
