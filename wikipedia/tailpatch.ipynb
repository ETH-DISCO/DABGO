{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fccf741",
   "metadata": {},
   "source": [
    "# Tailpatch scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TailPatch Function: With Log Likelihood\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "import math\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def tp_debug_log(samples,output_ids, prompt_length=1):\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)  \n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        samples,\n",
    "        batch_size=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    device = 'cpu'\n",
    "    model = GPT2LMHeadModel.from_pretrained('out/gpt2-scratch-mixed')\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    with torch.no_grad():\n",
    "        model_pass = model(output_ids, labels=output_ids)\n",
    "\n",
    "    logits = model_pass.logits\n",
    "    logits = logits[:, prompt_length-1:-1, :]\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "    target_ids = output_ids[:, prompt_length:]\n",
    "    token_probs = log_probs.gather(2, target_ids.unsqueeze(-1))\n",
    "    token_probs = token_probs.squeeze(-1)\n",
    "    print(tokenizer.decode(target_ids[0], skip_special_tokens=True))\n",
    "    original_probability = 0\n",
    "    for i in range(token_probs.shape[1]):\n",
    "        original_probability += token_probs[0,i]\n",
    "    original_probability = math.exp(original_probability.item())\n",
    "    print('Original Probability:', original_probability)\n",
    "    original_probs = token_probs.clone()\n",
    "\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        del input_ids, attention_mask, outputs, labels, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_pass = model(output_ids, labels=output_ids)\n",
    "\n",
    "    logits = model_pass.logits\n",
    "    logits = logits[:, prompt_length-1:-1, :]\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "    target_ids = output_ids[:, prompt_length:]\n",
    "    token_probs = log_probs.gather(2, target_ids.unsqueeze(-1))\n",
    "    token_probs = token_probs.squeeze(-1)\n",
    "    probability = 1\n",
    "    for i in range(token_probs.shape[1]):\n",
    "        probability += token_probs[0,i]\n",
    "    probability = math.exp(probability.item())   \n",
    "    return probability, original_probability, token_probs, original_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1057ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_dataset = load_from_disk(\"data/training_data/tokenized_wit_dataset/train\")\n",
    "eval_dataset = load_from_disk(\"data/training_data/tokenized_wit_dataset/test\")\n",
    "from rank_bm25 import BM25Okapi\n",
    "import torch\n",
    "corpus = torch.load('data/training_data/untokenized_wiki.pt', map_location='cpu')\n",
    "print(f\"Loaded {len(corpus)} documents.\")\n",
    "print(\"Sample:\", corpus[0][:300])\n",
    "corpus = np.array(corpus)\n",
    "print(len(corpus))\n",
    "tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f973e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    'ancient_rome',\n",
    "    'impressionism',\n",
    "    'ww2',\n",
    "    'dna',\n",
    "    'solar_system',\n",
    "    'philosophy_mind',\n",
    "    'jazz',\n",
    "    'thermodynamics',\n",
    "    'internet',\n",
    "    'feminism',\n",
    "    'everest',\n",
    "    'iss',\n",
    "    'ww1',\n",
    "    'ancient_egypt',\n",
    "    'ancient_greece',\n",
    "    'art_deco',\n",
    "    'big_bang',\n",
    "    'buddhism',\n",
    "    'democracy',\n",
    "    'ecology',\n",
    "    'genetics',\n",
    "    'gothic_architecture',\n",
    "    'probability',\n",
    "    'renaissance',\n",
    "    'shakespeare'\n",
    "]\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "dfs = []\n",
    "for example in examples[13:]:\n",
    "    print(example)\n",
    "    ckpt = torch.load(f'out/wiki_models_finetuned/fisher_regularized_models/{example}_finetuned_fisher.pt', map_location='cpu')\n",
    "    output_ids = ckpt['output_ids']\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    print(output_text)\n",
    "    splits = output_text.split('.')\n",
    "    prompt = splits[0]+'.'\n",
    "    print(prompt)\n",
    "    prompt_length = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    prompt_length = len(prompt_length)\n",
    "    print(prompt_length)\n",
    "    losses_af = np.load(f'data/losses/wiki/finetuned/fisher_regularized/{example}_finetuned.npy')\n",
    "    losses_bf = np.load(f'data/losses/wiki/losses_bf.npy')\n",
    "    losses_diff = losses_bf - losses_af\n",
    "    sorted_indices = np.argsort(losses_diff)\n",
    "    samples_ft = []\n",
    "    for i in range(20):\n",
    "        print(tokenizer.decode(train_dataset[int(sorted_indices[i])]['input_ids'], skip_special_tokens=True))\n",
    "        print('----------------------------------------')\n",
    "        sample_ft = {\n",
    "            'input_ids': torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids'])\n",
    "        }\n",
    "        samples_ft.append(sample_ft)\n",
    "    p_1, original, _, _ = tp_debug_log(samples_ft[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3, original, _, _ = tp_debug_log(samples_ft[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5, original, _, _ = tp_debug_log(samples_ft[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7, original, _, _ = tp_debug_log(samples_ft[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10, original, _, _ = tp_debug_log(samples_ft[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15, original, _, _ = tp_debug_log(samples_ft[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20, original, _, _ = tp_debug_log(samples_ft[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    dfs.append({\n",
    "        'method': 'Finetuning',\n",
    "        'name': example,\n",
    "        '1': p_1,\n",
    "        '3': p_3,\n",
    "        '5': p_5,\n",
    "        '7': p_7,\n",
    "        '10': p_10,\n",
    "        '15': p_15,\n",
    "        '20': p_20\n",
    "    })\n",
    "    dfs.append({\n",
    "        'method': 'Original',\n",
    "        'name': example,\n",
    "        '1': original,\n",
    "        '3': original,\n",
    "        '5': original,\n",
    "        '7': original,\n",
    "        '10': original,\n",
    "        '15': original,\n",
    "        '20': original\n",
    "    })\n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    losses_unlearned = np.load(f'data/losses/wiki/unlearned/fisher_regularized/{example}_unlearned.npy')\n",
    "    losses_diff_unlearned = np.abs(losses_af - losses_unlearned)\n",
    "    sorted_indices_unlearned = np.argsort(losses_diff_unlearned)[::-1]\n",
    "    samples_un_ft = []\n",
    "    for i in range(20):\n",
    "        print(tokenizer.decode(train_dataset[int(sorted_indices_unlearned[i])]['input_ids'], skip_special_tokens=True))\n",
    "        print('----------------------------------------')\n",
    "        sample_un_ft = {\n",
    "            'input_ids': torch.tensor(train_dataset[int(sorted_indices_unlearned[i])]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[int(sorted_indices_unlearned[i])]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[int(sorted_indices_unlearned[i])]['input_ids'])\n",
    "        }\n",
    "        samples_un_ft.append(sample_un_ft)\n",
    "    p_1_un, original_un, _, _ = tp_debug_log(samples_un_ft[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3_un, original_un, _, _ = tp_debug_log(samples_un_ft[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5_un, original_un, _, _ = tp_debug_log(samples_un_ft[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7_un, original_un, _, _ = tp_debug_log(samples_un_ft[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10_un, original_un, _, _ = tp_debug_log(samples_un_ft[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15_un, original_un, _, _ = tp_debug_log(samples_un_ft[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20_un, original_un, _, _ = tp_debug_log(samples_un_ft[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    dfs.append({\n",
    "        'method': 'FT & UN',\n",
    "        'name': example,\n",
    "        '1': p_1_un,\n",
    "        '3': p_3_un,\n",
    "        '5': p_5_un,\n",
    "        '7': p_7_un,\n",
    "        '10': p_10_un,\n",
    "        '15': p_15_un,\n",
    "        '20': p_20_un\n",
    "    })\n",
    "\n",
    "\n",
    "    losses_diff = losses_bf - losses_unlearned\n",
    "    sorted_indices_un = np.argsort(losses_diff)\n",
    "    samples_un = []\n",
    "    for i in range(20):\n",
    "        print(tokenizer.decode(train_dataset[int(sorted_indices_un[i])]['input_ids'], skip_special_tokens=True))\n",
    "        print('----------------------------------------')\n",
    "        sample_un = {\n",
    "            'input_ids': torch.tensor(train_dataset[int(sorted_indices_un[i])]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[int(sorted_indices_un[i])]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[int(sorted_indices_un[i])]['input_ids'])\n",
    "        }\n",
    "        samples_un.append(sample_un)\n",
    "    p_1_un, original_un, _, _ = tp_debug_log(samples_un[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3_un, original_un, _, _ = tp_debug_log(samples_un[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5_un, original_un, _, _ = tp_debug_log(samples_un[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7_un, original_un, _, _ = tp_debug_log(samples_un[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10_un, original_un, _, _ = tp_debug_log(samples_un[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15_un, original_un, _, _ = tp_debug_log(samples_un[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20_un, original_un, _, _ = tp_debug_log(samples_un[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    dfs.append({\n",
    "        'method': 'Unlearning',\n",
    "        'name': example,\n",
    "        '1': p_1_un,\n",
    "        '3': p_3_un,\n",
    "        '5': p_5_un,\n",
    "        '7': p_7_un,\n",
    "        '10': p_10_un,\n",
    "        '15': p_15_un,\n",
    "        '20': p_20_un\n",
    "    })\n",
    "    print('----------------------------------------')\n",
    "    query = tokenizer.decode(output_ids[0, prompt_length:], skip_special_tokens=True)\n",
    "    print(query)\n",
    "    tokenized_query = query.lower().split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_n = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "    samples_bm25 = []\n",
    "    for rank, (idx, score) in enumerate(top_n, 1):\n",
    "        print(f\"\\nTop {rank} (index: {idx}, score: {score:.2f}):\\n{corpus[idx][:300]}\")\n",
    "        print(tokenizer.decode(train_dataset[idx]['input_ids'], skip_special_tokens=True))\n",
    "        sample_bm25 = {\n",
    "            'input_ids': torch.tensor(train_dataset[idx]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[idx]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[idx]['input_ids'])\n",
    "        }\n",
    "        samples_bm25.append(sample_bm25)\n",
    "\n",
    "    p_1, original, _, _ = tp_debug_log(samples_bm25[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3, original, _, _ = tp_debug_log(samples_bm25[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5, original, _, _ = tp_debug_log(samples_bm25[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7, original, _, _ = tp_debug_log(samples_bm25[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10, original, _, _ = tp_debug_log(samples_bm25[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15, original, _, _ = tp_debug_log(samples_bm25[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20, original, _, _ = tp_debug_log(samples_bm25[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "\n",
    "    dfs.append({\n",
    "        'name': example,\n",
    "        'method': 'BM25',\n",
    "        '1': p_1,\n",
    "        '3': p_3,\n",
    "        '5': p_5,\n",
    "        '7': p_7,\n",
    "        '10': p_10,\n",
    "        '15': p_15,\n",
    "        '20': p_20\n",
    "    })\n",
    "\n",
    "    trackstar_influence = np.load(f'data/training_data/trackstar/wiki/testing/gradients/influence_list_{example}_dot_model.npy')\n",
    "    print(trackstar_influence.shape)\n",
    "    trackstar_influence = trackstar_influence[:len(train_dataset)] ## When running in chunks, last couple items are empty\n",
    "    sorted_indices = np.argsort(trackstar_influence)[::-1]\n",
    "    samples_ft = []\n",
    "    for i in range(20):\n",
    "        sample_ft = {\n",
    "            'input_ids': torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[int(sorted_indices[i])]['input_ids'])\n",
    "        }\n",
    "        samples_ft.append(sample_ft)\n",
    "    \n",
    "    p_1, original, _, _ = tp_debug_log(samples_ft[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3, original, _, _ = tp_debug_log(samples_ft[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5, original, _, _ = tp_debug_log(samples_ft[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7, original, _, _ = tp_debug_log(samples_ft[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10, original, _, _ = tp_debug_log(samples_ft[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15, original, _, _ = tp_debug_log(samples_ft[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20, original, _, _ = tp_debug_log(samples_ft[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    dfs.append({\n",
    "        'method': 'TrackStar',\n",
    "        'name': example,\n",
    "        '1': p_1,\n",
    "        '3': p_3,\n",
    "        '5': p_5,\n",
    "        '7': p_7,\n",
    "        '10': p_10,\n",
    "        '15': p_15,\n",
    "        '20': p_20\n",
    "    })\n",
    "    random_samples = np.random.choice(len(train_dataset), size=20)\n",
    "    samples_random = []\n",
    "    for sample in random_samples:\n",
    "        print(tokenizer.decode(train_dataset[int(sample)]['input_ids'], skip_special_tokens=True))\n",
    "        samples_random.append({\n",
    "            'input_ids': torch.tensor(train_dataset[int(sample)]['input_ids']),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(train_dataset[int(sample)]['input_ids'])),\n",
    "            'labels': torch.tensor(train_dataset[int(sample)]['input_ids'])\n",
    "        })\n",
    "    p_1, original, _, _ = tp_debug_log(samples_random[:1],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_3, original, _, _ = tp_debug_log(samples_random[:3],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_5, original, _, _ = tp_debug_log(samples_random[:5],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_7, original, _, _ = tp_debug_log(samples_random[:7],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_10, original, _, _ = tp_debug_log(samples_random[:10],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_15, original, _, _ = tp_debug_log(samples_random[:15],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    p_20, original, _, _ = tp_debug_log(samples_random[:20],output_ids=output_ids, prompt_length=prompt_length)\n",
    "    dfs.append({\n",
    "        'method': 'Random',\n",
    "        'name': example,\n",
    "        '1': p_1,\n",
    "        '3': p_3,\n",
    "        '5': p_5,\n",
    "        '7': p_7,\n",
    "        '10': p_10,\n",
    "        '15': p_15,\n",
    "        '20': p_20\n",
    "    })\n",
    "    total_df = pd.DataFrame(dfs)\n",
    "    os.makedirs('data/results', exist_ok=True)\n",
    "    total_df.to_csv(f'data/results/results_aggregated.csv', index=False)\n",
    "    print('\\n\\n\\n\\n')\n",
    "total_df = pd.DataFrame(dfs)\n",
    "os.makedirs('data/results', exist_ok=True)\n",
    "total_df.to_csv('data/results/results_aggregated.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/results/results_aggregated.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cols_to_check = ['1', '3', '5', '7', '10', '15', '20']\n",
    "\n",
    "# Ensure those columns are strings, if they are originally float or int\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "results = []\n",
    "\n",
    "for namegrouped, group in df.groupby('name'):\n",
    "    original_row = group[group['method'].str.lower() == 'original']\n",
    "    if original_row.empty:\n",
    "        print(namegrouped)\n",
    "        continue\n",
    "    original_values = original_row[cols_to_check].iloc[0]\n",
    "    \n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        if row['method'].lower() == 'original':\n",
    "            continue\n",
    "        rel_increase =np.abs(((row[cols_to_check].astype(float)) - (original_values.astype(float))) / np.abs(original_values.astype(float))) * 100\n",
    "        result_row = {\n",
    "            'name': namegrouped,\n",
    "            'method': row['method'],\n",
    "        }\n",
    "        for col in cols_to_check:\n",
    "            result_row[f'rel_increase_{col}'] = rel_increase[col]\n",
    "        results.append(result_row)\n",
    "\n",
    "# Final result\n",
    "rel_df = pd.DataFrame(results)\n",
    "\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c886be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = (\n",
    "    rel_df.groupby(['method'])\n",
    "    .agg({\n",
    "        'rel_increase_1': ['mean', 'std'],\n",
    "        'rel_increase_3': ['mean', 'std'],\n",
    "        'rel_increase_5': ['mean', 'std'],\n",
    "        'rel_increase_7': ['mean', 'std'],\n",
    "        'rel_increase_10': ['mean', 'std'],\n",
    "        'rel_increase_15': ['mean', 'std'],\n",
    "        'rel_increase_20': ['mean', 'std'],\n",
    "    })\n",
    ")\n",
    "avg_df = avg_df.round(2)\n",
    "avg_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cleaned = avg_df.loc[:, avg_df.columns.get_level_values(1) == 'mean']\n",
    "df_cleaned.columns = [col[0].split('_')[-1] for col in df_cleaned.columns]\n",
    "\n",
    "df_cleaned.columns.name = None\n",
    "df_cleaned.index.name = None\n",
    "df_cleaned = df_cleaned.sort_values(by=['1'], ascending=True)\n",
    "df_cleaned.rename(index={'FT/UN': 'FT & UN'}, inplace=True)\n",
    "df_cleaned_original = pd.concat([df_cleaned.loc[[\"BM25\"]], df_cleaned.drop(index=\"BM25\")])\n",
    "#df_cleaned.to_csv('avg_df_fisher_raw_.csv', index=True)\n",
    "df_cleaned_original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_1 = pd.read_csv('../data/results/avg_results_with_gecko.csv', index_col=0)\n",
    "df_2 = pd.read_csv('../data/results/avg_df_gutenberg_raw.csv', index_col=0)\n",
    "df_1 = df_1.drop(columns=['num_steps'])\n",
    "df_2.rename(index={'UN - BF': 'Unlearning'}, inplace=True)\n",
    "df_2.rename(index={'BF - FT': 'Finetuning'}, inplace=True)\n",
    "combined = pd.concat([df_1, df_2], axis=1, keys=[\"Wikipedia\", \"Gutenberg\"])\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read\n",
    "df_1 = pd.read_csv('../data/results/avg_results_with_gecko.csv', index_col=0)\n",
    "df_2 = pd.read_csv('../data/results/avg_df_gutenberg_gecko.csv', index_col=0)\n",
    "\n",
    "# Keep only the models of interest (by index) in df_1\n",
    "wanted = ['BM25', 'TrackStar', 'Random', 'FT & UN', 'Gecko']\n",
    "df_1 = df_1.loc[df_1.index.intersection(wanted)]\n",
    "# (optional) order rows as in `wanted`\n",
    "df_1 = df_1.reindex(wanted).dropna(how='all')\n",
    "\n",
    "# Drop extra column present only in df_1\n",
    "if 'num_steps' in df_1.columns:\n",
    "    df_1 = df_1.drop(columns=['num_steps'])\n",
    "\n",
    "# Harmonize names in df_2\n",
    "df_2 = df_2.rename(index={'UN - BF': 'Unlearning', 'BF - FT': 'Finetuning'})\n",
    "\n",
    "# (optional) align df_2 to a desired order; adapt as needed\n",
    "order_gut = ['BM25', 'TrackStar', 'Random', 'FT & UN', 'Gecko']\n",
    "df_2 = df_2.loc[df_2.index.intersection(order_gut)].reindex(order_gut).dropna(how='all')\n",
    "\n",
    "# Combine with MultiIndex columns\n",
    "combined = pd.concat([df_1, df_2], axis=1, keys=[\"Wikipedia\", \"Gutenberg\"])\n",
    "\n",
    "combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20494060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define levels: Dataset, Top-k (%), and specific k values\n",
    "k_vals = [1, 3, 5, 7, 10, 15, 20]\n",
    "datasets = [\"Wikipedia\", \"Gutenberg\"]\n",
    "topk_level = [\"Top-k (\\\\%)\"] * len(k_vals) * len(datasets)\n",
    "dataset_level = sum([[d] * len(k_vals) for d in datasets], [])\n",
    "k_level = k_vals * len(datasets)\n",
    "\n",
    "# Assign new MultiIndex\n",
    "combined.columns = pd.MultiIndex.from_arrays([dataset_level, topk_level, k_level])\n",
    "\n",
    "def format_latex(df):\n",
    "    df_fmt = df.copy().astype(str)\n",
    "    datasets = df.columns.levels[0]\n",
    "    topks = df.columns.levels[2]\n",
    "\n",
    "    for dataset in datasets:\n",
    "        for k in topks:\n",
    "            col_vals = df[(dataset, \"Top-k (\\\\%)\", k)]\n",
    "            sorted_vals = col_vals.sort_values(ascending=False)\n",
    "            if len(sorted_vals) < 2:\n",
    "                continue\n",
    "            top1, top2 = sorted_vals.index[0], sorted_vals.index[1]\n",
    "            for idx in col_vals.index:\n",
    "                val = col_vals.loc[idx]\n",
    "                if idx == top1:\n",
    "                    df_fmt.loc[idx, (dataset, \"Top-k (\\\\%)\", k)] = f\"\\\\textbf{{{val:.1f}}}\"\n",
    "                elif idx == top2:\n",
    "                    df_fmt.loc[idx, (dataset, \"Top-k (\\\\%)\", k)] = f\"\\\\underline{{{val:.1f}}}\"\n",
    "                else:\n",
    "                    df_fmt.loc[idx, (dataset, \"Top-k (\\\\%)\", k)] = f\"{val:.1f}\"\n",
    "    return df_fmt\n",
    "\n",
    "formatted_df = format_latex(combined)\n",
    "latex_code = formatted_df.to_latex(\n",
    "    escape=False,\n",
    "    multicolumn=True,\n",
    "    multirow=True,\n",
    "    column_format='l' + 'r'*7 + '|' + 'r'*7,\n",
    "    index_names=False\n",
    ")\n",
    "\n",
    "\n",
    "# Replace left-aligned dataset headers with centered ones\n",
    "latex_code = latex_code.replace(\n",
    "    r'\\multicolumn{7}{l}{Wikipedia}', r'\\multicolumn{7}{c}{\\textbf{Wikipedia}}'\n",
    ")\n",
    "latex_code = latex_code.replace(\n",
    "    r'\\multicolumn{7}{l}{Gutenberg}', r'\\multicolumn{7}{c}{\\textbf{Gutenberg}}'\n",
    ")\n",
    "\n",
    "# Print LaTeX\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadc646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9111cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa542e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50005ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa6cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
